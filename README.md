# arxiv-daily
 Automated deployment @ 2025-06-09 21:25:52 Asia/Shanghai
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/beiyuouo/arxiv-daily/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/beiyuouo/arxiv-daily/blob/main/database/storage).

## Multi-modal

### CLIP
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-06-06**|**HAVIR: HierArchical Vision to Image Reconstruction using CLIP-Guided Versatile Diffusion**|Shiyi Zhang et.al.|[2506.06035v1](http://arxiv.org/abs/2506.06035v1)|null|
|**2025-06-06**|**LLIA -- Enabling Low-Latency Interactive Avatars: Real-Time Audio-Driven Portrait Video Generation with Diffusion Models**|Haojie Yu et.al.|[2506.05806v1](http://arxiv.org/abs/2506.05806v1)|null|
|**2025-06-05**|**FRAME: Pre-Training Video Feature Representations via Anticipation and Memory**|Sethuraman TV et.al.|[2506.05543v1](http://arxiv.org/abs/2506.05543v1)|null|
|**2025-06-05**|**MORSE-500: A Programmatically Controllable Video Benchmark to Stress-Test Multimodal Reasoning**|Zikui Cai et.al.|[2506.05523v1](http://arxiv.org/abs/2506.05523v1)|null|
|**2025-06-05**|**MARBLE: Material Recomposition and Blending in CLIP-Space**|Ta-Ying Cheng et.al.|[2506.05313v1](http://arxiv.org/abs/2506.05313v1)|null|
|**2025-06-05**|**From Play to Replay: Composed Video Retrieval for Temporally Fine-Grained Videos**|Animesh Gupta et.al.|[2506.05274v1](http://arxiv.org/abs/2506.05274v1)|null|
|**2025-06-05**|**Tuning the Right Foundation Models is What you Need for Partial Label Learning**|Kuang He et.al.|[2506.05027v1](http://arxiv.org/abs/2506.05027v1)|null|
|**2025-06-05**|**Beyond Cropped Regions: New Benchmark and Corresponding Baseline for Chinese Scene Text Retrieval in Diverse Layouts**|Gengluo Li et.al.|[2506.04999v1](http://arxiv.org/abs/2506.04999v1)|null|
|**2025-06-05**|**LLMs Can Compensate for Deficiencies in Visual Representations**|Sho Takishita et.al.|[2506.05439v1](http://arxiv.org/abs/2506.05439v1)|null|
|**2025-06-05**|**Learning dissection trajectories from expert surgical videos via imitation learning with equivariant diffusion**|Hongyu Wang et.al.|[2506.04716v1](http://arxiv.org/abs/2506.04716v1)|null|
|**2025-06-05**|**SIV-Bench: A Video Benchmark for Social Interaction Understanding and Reasoning**|Fanqi Kong et.al.|[2506.05425v1](http://arxiv.org/abs/2506.05425v1)|null|
|**2025-06-05**|**Scaling Laws for Robust Comparison of Open Foundation Language-Vision Models and Datasets**|Marianna Nezhurina et.al.|[2506.04598v1](http://arxiv.org/abs/2506.04598v1)|null|
|**2025-06-05**|**Handle-based Mesh Deformation Guided By Vision Language Model**|Xingpeng Sun et.al.|[2506.04562v1](http://arxiv.org/abs/2506.04562v1)|null|
|**2025-06-04**|**Normalize Filters! Classical Wisdom for Deep Vision**|Gustavo Perez et.al.|[2506.04401v1](http://arxiv.org/abs/2506.04401v1)|null|
|**2025-06-04**|**Hierarchical Text Classification Using Contrastive Learning Informed Path Guided Hierarchy**|Neeraj Agrawal et.al.|[2506.04381v1](http://arxiv.org/abs/2506.04381v1)|null|
|**2025-06-04**|**Fine-Tuning Video Transformers for Word-Level Bangla Sign Language: A Comparative Analysis for Classification Tasks**|Jubayer Ahmed Bhuiyan Shawon et.al.|[2506.04367v1](http://arxiv.org/abs/2506.04367v1)|null|
|**2025-06-04**|**LayerFlow: A Unified Model for Layer-aware Video Generation**|Sihui Ji et.al.|[2506.04228v1](http://arxiv.org/abs/2506.04228v1)|null|
|**2025-06-04**|**Language-Image Alignment with Fixed Text Encoders**|Jingfeng Yang et.al.|[2506.04209v1](http://arxiv.org/abs/2506.04209v1)|null|
|**2025-06-04**|**Multiple Stochastic Prompt Tuning for Practical Cross-Domain Few Shot Learning**|Debarshi Brahma et.al.|[2506.03926v1](http://arxiv.org/abs/2506.03926v1)|null|
|**2025-06-04**|**AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives**|Aniruddh Sikdar et.al.|[2506.03709v1](http://arxiv.org/abs/2506.03709v1)|null|
|**2025-06-04**|**OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation**|Aditya Gandhamal et.al.|[2506.03706v1](http://arxiv.org/abs/2506.03706v1)|null|
|**2025-06-04**|**GCFL: A Gradient Correction-based Federated Learning Framework for Privacy-preserving CPSS**|Jiayi Wan et.al.|[2506.03618v1](http://arxiv.org/abs/2506.03618v1)|null|
|**2025-06-04**|**Isharah: A Large-Scale Multi-Scene Dataset for Continuous Sign Language Recognition**|Sarah Alyami et.al.|[2506.03615v1](http://arxiv.org/abs/2506.03615v1)|null|
|**2025-06-04**|**DenseDPO: Fine-Grained Temporal Preference Optimization for Video Diffusion Models**|Ziyi Wu et.al.|[2506.03517v1](http://arxiv.org/abs/2506.03517v1)|null|
|**2025-06-03**|**Cross-Modal Urban Sensing: Evaluating Sound-Vision Alignment Across Street-Level and Aerial Imagery**|Pengyu Chen et.al.|[2506.03388v1](http://arxiv.org/abs/2506.03388v1)|null|
|**2025-06-03**|**Robustness in Both Domains: CLIP Needs a Robust Text Encoder**|Elias Abad Rocamora et.al.|[2506.03355v1](http://arxiv.org/abs/2506.03355v1)|null|
|**2025-06-03**|**Talk2SAM: Text-Guided Semantic Enhancement for Complex-Shaped Object Segmentation**|Luka Vetoshkin et.al.|[2506.05396v1](http://arxiv.org/abs/2506.05396v1)|null|
|**2025-06-03**|**Attacking Attention of Foundation Models Disrupts Downstream Tasks**|Hondamunige Prasanna Silva et.al.|[2506.05394v1](http://arxiv.org/abs/2506.05394v1)|null|
|**2025-06-03**|**AnimeShooter: A Multi-Shot Animation Dataset for Reference-Guided Video Generation**|Lu Qiu et.al.|[2506.03126v1](http://arxiv.org/abs/2506.03126v1)|null|
|**2025-06-03**|**Targeted Forgetting of Image Subgroups in CLIP Models**|Zeliang Zhang et.al.|[2506.03117v1](http://arxiv.org/abs/2506.03117v1)|null|

### Multi-modal
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-06-06**|**TerraFM: A Scalable Foundation Model for Unified Multisensor Earth Observation**|Muhammad Sohail Danish et.al.|[2506.06281v1](http://arxiv.org/abs/2506.06281v1)|null|
|**2025-06-06**|**CoMemo: LVLMs Need Image Context with Image Memory**|Shi Liu et.al.|[2506.06279v1](http://arxiv.org/abs/2506.06279v1)|null|
|**2025-06-06**|**The Atacama Cosmology Telescope: DR6 Power Spectrum Foreground Model and Validation**|Benjamin Beringue et.al.|[2506.06274v1](http://arxiv.org/abs/2506.06274v1)|null|
|**2025-06-06**|**BecomingLit: Relightable Gaussian Avatars with Hybrid Neural Shading**|Jonathan Schmidt et.al.|[2506.06271v1](http://arxiv.org/abs/2506.06271v1)|null|
|**2025-06-06**|**From NLVO to NAO: Reactive Robot Navigation using Velocity and Acceleration Obstacles**|Asher Stern et.al.|[2506.06255v1](http://arxiv.org/abs/2506.06255v1)|null|
|**2025-06-06**|**DesignBench: A Comprehensive Benchmark for MLLM-based Front-end Code Generation**|Jingyu Xiao et.al.|[2506.06251v1](http://arxiv.org/abs/2506.06251v1)|null|
|**2025-06-06**|**Visual Graph Arena: Evaluating Visual Conceptualization of Vision and Multimodal Large Language Models**|Zahra Babaiee et.al.|[2506.06242v1](http://arxiv.org/abs/2506.06242v1)|null|
|**2025-06-06**|**Optimizing Recall or Relevance? A Multi-Task Multi-Head Approach for Item-to-Item Retrieval in Recommendation**|Jiang Zhang et.al.|[2506.06239v1](http://arxiv.org/abs/2506.06239v1)|null|
|**2025-06-06**|**GenIR: Generative Visual Feedback for Mental Image Retrieval**|Diji Yang et.al.|[2506.06220v1](http://arxiv.org/abs/2506.06220v1)|null|
|**2025-06-06**|**STSBench: A Spatio-temporal Scenario Benchmark for Multi-modal Large Language Models in Autonomous Driving**|Christian Fruhwirth-Reisinger et.al.|[2506.06218v1](http://arxiv.org/abs/2506.06218v1)|null|
|**2025-06-06**|**Can Theoretical Physics Research Benefit from Language Agents?**|Sirui Lu et.al.|[2506.06214v1](http://arxiv.org/abs/2506.06214v1)|null|
|**2025-06-06**|**PuzzleWorld: A Benchmark for Multimodal, Open-Ended Reasoning in Puzzlehunts**|Hengzhi Li et.al.|[2506.06211v1](http://arxiv.org/abs/2506.06211v1)|null|
|**2025-06-06**|**Building Models of Neurological Language**|Henry Watkins et.al.|[2506.06208v1](http://arxiv.org/abs/2506.06208v1)|null|
|**2025-06-06**|**Astra: Toward General-Purpose Mobile Robots via Hierarchical Multimodal Learning**|Sheng Chen et.al.|[2506.06205v1](http://arxiv.org/abs/2506.06205v1)|null|
|**2025-06-06**|**How to craft a deep reinforcement learning policy for wind farm flow control**|Elie Kadoche et.al.|[2506.06204v1](http://arxiv.org/abs/2506.06204v1)|null|
|**2025-06-06**|**TOI-2407 b: a warm Neptune in the desert**|C. Janó Muñoz et.al.|[2506.06195v1](http://arxiv.org/abs/2506.06195v1)|null|
|**2025-06-06**|**A Theoretical Study of (Hyper) Self-Attention through the Lens of Interactions: Representation, Training, Generalization**|Muhammed Ustaomeroglu et.al.|[2506.06179v1](http://arxiv.org/abs/2506.06179v1)|null|
|**2025-06-06**|**SatelliteFormula: Multi-Modal Symbolic Regression from Remote Sensing Imagery for Physics Discovery**|Zhenyu Yu et.al.|[2506.06176v1](http://arxiv.org/abs/2506.06176v1)|null|
|**2025-06-06**|**Does It Run and Is That Enough? Revisiting Text-to-Chart Generation with a Multi-Agent Approach**|James Ford et.al.|[2506.06175v1](http://arxiv.org/abs/2506.06175v1)|null|
|**2025-06-06**|**Monitorability for the Modal mu-Calculus over Systems with Data: From Practice to Theory**|Luca Aceto et.al.|[2506.06172v1](http://arxiv.org/abs/2506.06172v1)|null|
|**2025-06-06**|**(AI peers) are people learning from the same standpoint: Perception of AI characters in a Collaborative Science Investigation**|Eunhye Grace Ko et.al.|[2506.06165v1](http://arxiv.org/abs/2506.06165v1)|null|
|**2025-06-06**|**Vector Boson Fusion Signatures of Superheavy Majorana Neutrinos at Muon Colliders**|Parham Dehghani et.al.|[2506.06159v1](http://arxiv.org/abs/2506.06159v1)|null|
|**2025-06-06**|**Masked Language Models are Good Heterogeneous Graph Generalizers**|Jinyu Yang et.al.|[2506.06157v1](http://arxiv.org/abs/2506.06157v1)|null|
|**2025-06-06**|**A Novel Large-scale Crop Dataset and Dual-stream Transformer Method for Fine-grained Hierarchical Crop Classification from Integrated Hyperspectral EnMAP Data and Multispectral Sentinel-2 Time Series**|Wenyuan Li et.al.|[2506.06155v1](http://arxiv.org/abs/2506.06155v1)|null|
|**2025-06-06**|**CLaMR: Contextualized Late-Interaction for Multimodal Content Retrieval**|David Wan et.al.|[2506.06144v1](http://arxiv.org/abs/2506.06144v1)|null|
|**2025-06-06**|**carps: A Framework for Comparing N Hyperparameter Optimizers on M Benchmarks**|Carolin Benjamins et.al.|[2506.06143v1](http://arxiv.org/abs/2506.06143v1)|null|
|**2025-06-06**|**Gradient Similarity Surgery in Multi-Task Deep Learning**|Thomas Borsani et.al.|[2506.06130v1](http://arxiv.org/abs/2506.06130v1)|null|
|**2025-06-06**|**CCLSTM: Coupled Convolutional Long-Short Term Memory Network for Occupancy Flow Forecasting**|Peter Lengyel et.al.|[2506.06128v1](http://arxiv.org/abs/2506.06128v1)|null|
|**2025-06-06**|**Decomposability-Guaranteed Cooperative Coevolution for Large-Scale Itinerary Planning**|Ziyu Zhang et.al.|[2506.06121v1](http://arxiv.org/abs/2506.06121v1)|null|
|**2025-06-06**|**Bridging the Gap: In-Context Learning for Modeling Human Disagreement**|Benedetta Muscato et.al.|[2506.06113v1](http://arxiv.org/abs/2506.06113v1)|null|

## Fashion

### Compatibility
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-06-06**|**A Sound and Complete Characterization of Fair Asynchronous Session Subtyping**|Mario Bravetti et.al.|[2506.06078v1](http://arxiv.org/abs/2506.06078v1)|null|
|**2025-06-06**|**BEAST: Efficient Tokenization of B-Splines Encoded Action Sequences for Imitation Learning**|Hongyi Zhou et.al.|[2506.06072v1](http://arxiv.org/abs/2506.06072v1)|null|
|**2025-06-06**|**CO-VADA: A Confidence-Oriented Voice Augmentation Debiasing Approach for Fair Speech Emotion Recognition**|Yun-Shao Tsai et.al.|[2506.06071v1](http://arxiv.org/abs/2506.06071v1)|null|
|**2025-06-06**|**MATP-BENCH: Can MLLM Be a Good Automated Theorem Prover for Multimodal Problems?**|Zhitao He et.al.|[2506.06034v1](http://arxiv.org/abs/2506.06034v1)|null|
|**2025-06-06**|**A Flexible Design Framework for Integrated Communication and Computing Receivers**|Kuranage Roche Rayan Ranasinghe et.al.|[2506.05944v1](http://arxiv.org/abs/2506.05944v1)|null|
|**2025-06-06**|**Spencer-Riemann-Roch Theory: Mirror Symmetry of Hodge Decompositions and Characteristic Classes in Constrained Geometry**|Dongzhe Zheng et.al.|[2506.05915v1](http://arxiv.org/abs/2506.05915v1)|null|
|**2025-06-06**|**Bayesian Persuasion as a Bargaining Game**|Yue Lin et.al.|[2506.05876v1](http://arxiv.org/abs/2506.05876v1)|null|
|**2025-06-06**|**Learning Along the Arrow of Time: Hyperbolic Geometry for Backward-Compatible Representation Learning**|Ngoc Bui et.al.|[2506.05826v1](http://arxiv.org/abs/2506.05826v1)|null|
|**2025-06-06**|**Mirror Symmetry of Spencer-Hodge Decompositions in Constrained Geometric Systems**|Dongzhe Zheng et.al.|[2506.05816v1](http://arxiv.org/abs/2506.05816v1)|null|
|**2025-06-06**|**Come Together, But Not Right Now: A Progressive Strategy to Boost Low-Rank Adaptation**|Zhan Zhuang et.al.|[2506.05713v1](http://arxiv.org/abs/2506.05713v1)|null|
|**2025-06-06**|**Latent Diffusion Model Based Denoising Receiver for 6G Semantic Communication: From Stochastic Differential Theory to Application**|Xiucheng Wang et.al.|[2506.05710v1](http://arxiv.org/abs/2506.05710v1)|null|
|**2025-06-06**|**Hybrid Stabilization Protocol for Cross-Chain Digital Assets Using Adaptor Signatures and AI-Driven Arbitrage**|Shengwei You et.al.|[2506.05708v1](http://arxiv.org/abs/2506.05708v1)|null|
|**2025-06-06**|**NGA: Non-autoregressive Generative Auction with Global Externalities for Advertising Systems**|Zuowu Zheng et.al.|[2506.05685v1](http://arxiv.org/abs/2506.05685v1)|null|
|**2025-06-05**|**S2GO: Streaming Sparse Gaussian Occupancy Prediction**|Jinhyung Park et.al.|[2506.05473v1](http://arxiv.org/abs/2506.05473v1)|null|
|**2025-06-05**|**Kilobyte-Scale, Selector-Free, Temperature-Hard AlScN Ferroelectric Diode Crossbar Arrays**|Zirun Han et.al.|[2506.05452v1](http://arxiv.org/abs/2506.05452v1)|null|
|**2025-06-05**|**SAM-aware Test-time Adaptation for Universal Medical Image Segmentation**|Jianghao Wu et.al.|[2506.05221v1](http://arxiv.org/abs/2506.05221v1)|null|
|**2025-06-05**|**Towards Vision-Language-Garment Models For Web Knowledge Garment Understanding and Generation**|Jan Ackermann et.al.|[2506.05210v1](http://arxiv.org/abs/2506.05210v1)|null|
|**2025-06-05**|**The non-Hermitian magnetic moment**|Bar Alon et.al.|[2506.05206v1](http://arxiv.org/abs/2506.05206v1)|null|
|**2025-06-05**|**Neural Jumps for Option Pricing**|Duosi Zheng et.al.|[2506.05137v1](http://arxiv.org/abs/2506.05137v1)|null|
|**2025-06-05**|**Bayesian ages of local young stellar associations I. Through the expansion rate method**|J. Olivares et.al.|[2506.05130v1](http://arxiv.org/abs/2506.05130v1)|null|
|**2025-06-05**|**Statistical microlocal analysis in two-dimensional X-ray CT**|Anuj Abhishek et.al.|[2506.05113v2](http://arxiv.org/abs/2506.05113v2)|null|
|**2025-06-05**|**Testing gravity with wide binaries -- 3D velocities and distances of wide binaries from Gaia and HARPS**|R. Saglia et.al.|[2506.05049v1](http://arxiv.org/abs/2506.05049v1)|null|
|**2025-06-05**|**Physical Annotation for Automated Optical Inspection: A Concept for In-Situ, Pointer-Based Trainingdata Generation**|Oliver Krumpek et.al.|[2506.05026v1](http://arxiv.org/abs/2506.05026v1)|null|
|**2025-06-05**|**Controlling Summarization Length Through EOS Token Weighting**|Zeno Belligoli et.al.|[2506.05017v1](http://arxiv.org/abs/2506.05017v1)|null|
|**2025-06-05**|**Light and 3D: a methodological exploration of digitisation techniques adapted to a selection of objects from the Mus{é}e d'Arch{é}ologie Nationale**|Antoine Laurent et.al.|[2506.04925v1](http://arxiv.org/abs/2506.04925v1)|null|
|**2025-06-05**|**Online matching on stochastic block model**|Maria Cherifa et.al.|[2506.04921v1](http://arxiv.org/abs/2506.04921v1)|null|
|**2025-06-05**|**Scattering angle in a Topological Star spacetime: a self-force approach**|Massimo Bianchi et.al.|[2506.04876v1](http://arxiv.org/abs/2506.04876v1)|null|
|**2025-06-05**|**Oversight Structures for Agentic AI in Public-Sector Organizations**|Chris Schmitz et.al.|[2506.04836v1](http://arxiv.org/abs/2506.04836v1)|null|
|**2025-06-05**|**Spike-TBR: a Noise Resilient Neuromorphic Event Representation**|Gabriele Magrini. Federico Becattini et.al.|[2506.04817v1](http://arxiv.org/abs/2506.04817v1)|null|
|**2025-06-05**|**Prefix Grouper: Efficient GRPO Training through Shared-Prefix Forward**|Zikang Liu et.al.|[2506.05433v1](http://arxiv.org/abs/2506.05433v1)|null|

### Virtual Try-On
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-05-29**|**VITON-DRR: Details Retention Virtual Try-on via Non-rigid Registration**|Ben Li et.al.|[2505.23439v1](http://arxiv.org/abs/2505.23439v1)|[link](https://github.com/minqili/viton-drr-main)|
|**2025-05-27**|**Inverse Virtual Try-On: Generating Multi-Category Product-Style Images from Clothed Individuals**|Davide Lobba et.al.|[2505.21062v1](http://arxiv.org/abs/2505.21062v1)|null|
|**2025-05-26**|**HF-VTON: High-Fidelity Virtual Try-On via Consistent Geometric and Semantic Alignment**|Ming Meng et.al.|[2505.19638v1](http://arxiv.org/abs/2505.19638v1)|[link](https://github.com/mmlph/hf-vton)|
|**2025-05-22**|**Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction**|Dong Li et.al.|[2505.16980v1](http://arxiv.org/abs/2505.16980v1)|null|
|**2025-05-22**|**Incorporating Visual Correspondence into Diffusion Model for Virtual Try-On**|Siqi Wan et.al.|[2505.16977v1](http://arxiv.org/abs/2505.16977v1)|[link](https://github.com/hidream-ai/spm-diff)|
|**2025-04-17**|**Enhancing Person-to-Person Virtual Try-On with Multi-Garment Virtual Try-Off**|Riza Velioglu et.al.|[2504.13078v1](http://arxiv.org/abs/2504.13078v1)|[link](https://github.com/rizavelioglu/tryoffdiff)|
|**2025-03-11**|**MF-VITON: High-Fidelity Mask-Free Virtual Try-On with Minimal Input**|Zhenchen Wan et.al.|[2503.08650v1](http://arxiv.org/abs/2503.08650v1)|null|
|**2025-02-13**|**E-MD3C: Taming Masked Diffusion Transformers for Efficient Zero-Shot Object Customization**|Trung X. Pham et.al.|[2502.09164v1](http://arxiv.org/abs/2502.09164v1)|null|
|**2025-01-20**|**EfficientVITON: An Efficient Virtual Try-On Model using Optimized Diffusion Process**|Mostafa Atef et.al.|[2501.11776v1](http://arxiv.org/abs/2501.11776v1)|null|
|**2025-01-08**|**Enhancing Virtual Try-On with Synthetic Pairs and Error-Aware Noise Scheduling**|Nannan Li et.al.|[2501.04666v3](http://arxiv.org/abs/2501.04666v3)|null|
|**2025-01-07**|**HYB-VITON: A Hybrid Approach to Virtual Try-On Combining Explicit and Implicit Warping**|Kosuke Takemoto et.al.|[2501.03910v1](http://arxiv.org/abs/2501.03910v1)|[link](https://github.com/takesukeds/hyb-viton)|
|**2024-12-13**|**Dynamic Try-On: Taming Video Virtual Try-on with Dynamic Attention Mechanism**|Jun Zheng et.al.|[2412.09822v1](http://arxiv.org/abs/2412.09822v1)|null|
|**2024-12-11**|**TryOffAnyone: Tiled Cloth Generation from a Dressed Person**|Ioannis Xarchakos et.al.|[2412.08573v2](http://arxiv.org/abs/2412.08573v2)|[link](https://github.com/ixarchakos/try-off-anyone)|
|**2024-11-27**|**TryOffDiff: Virtual-Try-Off via High-Fidelity Garment Reconstruction using Diffusion Models**|Riza Velioglu et.al.|[2411.18350v1](http://arxiv.org/abs/2411.18350v1)|[link](https://github.com/rizavelioglu/tryoffdiff)|
|**2024-11-26**|**TED-VITON: Transformer-Empowered Diffusion Models for Virtual Try-On**|Zhenchen Wan et.al.|[2411.17017v3](http://arxiv.org/abs/2411.17017v3)|[link](https://github.com/zhenchenwan/ted-viton)|
|**2024-11-15**|**Try-On-Adapter: A Simple and Flexible Try-On Paradigm**|Hanzhong Guo et.al.|[2411.10187v1](http://arxiv.org/abs/2411.10187v1)|null|
|**2024-10-16**|**Surface plasmon resonance sensor based on a novel prism for the detection of a broad range of polymers**|Natalia A. Gutierrez Andrade et.al.|[2410.12440v2](http://arxiv.org/abs/2410.12440v2)|null|
|**2024-09-22**|**GlamTry: Advancing Virtual Try-On for High-End Accessories**|Ting-Yu Chang et.al.|[2409.14553v1](http://arxiv.org/abs/2409.14553v1)|null|
|**2024-09-12**|**Improving Virtual Try-On with Garment-focused Diffusion Models**|Siqi Wan et.al.|[2409.08258v1](http://arxiv.org/abs/2409.08258v1)|[link](https://github.com/siqi0905/gardiff)|
|**2024-09-02**|**DPDEdit: Detail-Preserved Diffusion Models for Multimodal Fashion Image Editing**|Xiaolong Wang et.al.|[2409.01086v2](http://arxiv.org/abs/2409.01086v2)|null|
|**2024-07-15**|**WildVidFit: Video Virtual Try-On in the Wild via Image-Based Controlled Diffusion Models**|Zijian He et.al.|[2407.10625v1](http://arxiv.org/abs/2407.10625v1)|null|
|**2024-07-04**|**DiCTI: Diffusion-based Clothing Designer via Text-guided Input**|Ajda Lampe et.al.|[2407.03901v1](http://arxiv.org/abs/2407.03901v1)|null|
|**2024-06-04**|**GraVITON: Graph based garment warping with attention guided inversion for Virtual-tryon**|Sanhita Pathak et.al.|[2406.02184v1](http://arxiv.org/abs/2406.02184v1)|null|
|**2024-05-28**|**VITON-DiT: Learning In-the-Wild Video Try-On from Human Dance Videos via Diffusion Transformers**|Jun Zheng et.al.|[2405.18326v2](http://arxiv.org/abs/2405.18326v2)|null|
|**2024-05-01**|**MMTryon: Multi-Modal Multi-Reference Control for High-Quality Fashion Generation**|Xujie Zhang et.al.|[2405.00448v4](http://arxiv.org/abs/2405.00448v4)|null|
|**2024-04-26**|**Tunnel Try-on: Excavating Spatial-temporal Tunnels for High-quality Virtual Try-on in Videos**|Zhengze Xu et.al.|[2404.17571v1](http://arxiv.org/abs/2404.17571v1)|null|
|**2024-04-26**|**FashionSD-X: Multimodal Fashion Garment Synthesis using Latent Diffusion**|Abhishek Kumar Singh et.al.|[2404.18591v1](http://arxiv.org/abs/2404.18591v1)|null|
|**2024-04-26**|**MV-VTON: Multi-View Virtual Try-On with Diffusion Models**|Haoyu Wang et.al.|[2404.17364v4](http://arxiv.org/abs/2404.17364v4)|[link](https://github.com/hywang2002/mv-vton)|
|**2024-04-22**|**FLDM-VTON: Faithful Latent Diffusion Model for Virtual Try-on**|Chenhui Wang et.al.|[2404.14162v3](http://arxiv.org/abs/2404.14162v3)|null|
|**2024-04-01**|**Texture-Preserving Diffusion Models for High-Fidelity Virtual Try-On**|Xu Yang et.al.|[2404.01089v1](http://arxiv.org/abs/2404.01089v1)|[link](https://github.com/gal4way/tpd)|

### Attribute
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-06-06**|**fairmetrics: An R package for group fairness evaluation**|Benjamin Smith et.al.|[2506.06243v1](http://arxiv.org/abs/2506.06243v1)|null|
|**2025-06-06**|**PROVSYN: Synthesizing Provenance Graphs for Data Augmentation in Intrusion Detection Systems**|Yi Huang et.al.|[2506.06226v1](http://arxiv.org/abs/2506.06226v1)|null|
|**2025-06-06**|**Thickness Dependence of Coercive Field in Ferroelectric Doped-Hafnium Oxide**|Revanth Koduru et.al.|[2506.06222v1](http://arxiv.org/abs/2506.06222v1)|null|
|**2025-06-06**|**CO-VADA: A Confidence-Oriented Voice Augmentation Debiasing Approach for Fair Speech Emotion Recognition**|Yun-Shao Tsai et.al.|[2506.06071v1](http://arxiv.org/abs/2506.06071v1)|null|
|**2025-06-06**|**TRUST: Test-time Resource Utilization for Superior Trustworthiness**|Haripriya Harikumar et.al.|[2506.06048v1](http://arxiv.org/abs/2506.06048v1)|null|
|**2025-06-06**|**Optimization-Free Universal Watermark Forgery with Regenerative Diffusion Models**|Chaoyi Zhu et.al.|[2506.06018v1](http://arxiv.org/abs/2506.06018v1)|null|
|**2025-06-06**|**On the Merits of LLM-Based Corpus Enrichment**|Gal Zur et.al.|[2506.06015v1](http://arxiv.org/abs/2506.06015v1)|null|
|**2025-06-06**|**A Flexible Design Framework for Integrated Communication and Computing Receivers**|Kuranage Roche Rayan Ranasinghe et.al.|[2506.05944v1](http://arxiv.org/abs/2506.05944v1)|null|
|**2025-06-06**|**Yule-Walker Estimation for Functional Time Series in Hilbert Space**|Ying Niu et.al.|[2506.05922v1](http://arxiv.org/abs/2506.05922v1)|null|
|**2025-06-06**|**Object Navigation with Structure-Semantic Reasoning-Based Multi-level Map and Multimodal Decision-Making LLM**|Chongshang Yan et.al.|[2506.05896v1](http://arxiv.org/abs/2506.05896v1)|null|
|**2025-06-06**|**FontAdapter: Instant Font Adaptation in Visual Text Generation**|Myungkyu Koo et.al.|[2506.05843v1](http://arxiv.org/abs/2506.05843v1)|null|
|**2025-06-06**|**Unusual Electron-Phonon Interactions in Highly Anisotropic Two-Dimensional $Ta_2$$Ni_3$$Te_5$**|Fei Wang et.al.|[2506.05809v1](http://arxiv.org/abs/2506.05809v1)|null|
|**2025-06-06**|**TADA: Training-free Attribution and Out-of-Domain Detection of Audio Deepfakes**|Adriana Stan et.al.|[2506.05802v1](http://arxiv.org/abs/2506.05802v1)|null|
|**2025-06-06**|**Exploring Microstructural Dynamics in Cryptocurrency Limit Order Books: Better Inputs Matter More Than Stacking Another Hidden Layer**|Haochuan et.al.|[2506.05764v1](http://arxiv.org/abs/2506.05764v1)|null|
|**2025-06-06**|**Statistically Valid Post-Deployment Monitoring Should Be Standard for AI-Based Digital Health**|Pavel Dolin et.al.|[2506.05701v1](http://arxiv.org/abs/2506.05701v1)|null|
|**2025-06-06**|**What Comes After Harm? Mapping Reparative Actions in AI through Justice Frameworks**|Sijia Xiao et.al.|[2506.05687v1](http://arxiv.org/abs/2506.05687v1)|null|
|**2025-06-06**|**Molecular dynamics of $cis$-polybutadiene across glass transition revealed by muonated-radical spin relaxation**|S. Takeshita et.al.|[2506.05665v1](http://arxiv.org/abs/2506.05665v1)|null|
|**2025-06-06**|**Effects of inert background gases and photo-illumination on three-color electromagnetically induced transparency of rubidium vapor**|Alisher Duspayev et.al.|[2506.05656v1](http://arxiv.org/abs/2506.05656v1)|null|
|**2025-06-06**|**Flow-induced vibration of twin-pipe model with varying mass and damping: A study using virtual physical framework**|Jiawei Shen et.al.|[2506.05649v1](http://arxiv.org/abs/2506.05649v1)|null|
|**2025-06-06**|**Learning to Weight Parameters for Data Attribution**|Shuangqi Li et.al.|[2506.05647v1](http://arxiv.org/abs/2506.05647v1)|null|
|**2025-06-05**|**Coherent phonon motions and ordered vacancy compound mediated quantum path interference in Cu-poor CuIn$_{x}$Ga$_{(1-x)}$Se$_2$ (CIGS) with attosecond transient absorption**|Hugo Laurell et.al.|[2506.05621v1](http://arxiv.org/abs/2506.05621v1)|null|
|**2025-06-05**|**Breaking Anonymity at Scale: Re-identifying the Trajectories of 100K Real Users in Japan**|Abhishek Kumar Mishra et.al.|[2506.05611v1](http://arxiv.org/abs/2506.05611v1)|null|
|**2025-06-05**|**Improving Neural Diarization through Speaker Attribute Attractors and Local Dependency Modeling**|David Palzer et.al.|[2506.05593v1](http://arxiv.org/abs/2506.05593v1)|null|
|**2025-06-05**|**CoFrNets: Interpretable Neural Architecture Inspired by Continued Fractions**|Isha Puri et.al.|[2506.05586v1](http://arxiv.org/abs/2506.05586v1)|null|
|**2025-06-05**|**Testing Hypotheses of Covariate Effects on Topics of Discourse**|Gabriel Phelan et.al.|[2506.05570v1](http://arxiv.org/abs/2506.05570v1)|null|
|**2025-06-05**|**S2GO: Streaming Sparse Gaussian Occupancy Prediction**|Jinhyung Park et.al.|[2506.05473v1](http://arxiv.org/abs/2506.05473v1)|null|
|**2025-06-05**|**Search Arena: Analyzing Search-Augmented LLMs**|Mihran Miroyan et.al.|[2506.05334v1](http://arxiv.org/abs/2506.05334v1)|null|
|**2025-06-05**|**MARBLE: Material Recomposition and Blending in CLIP-Space**|Ta-Ying Cheng et.al.|[2506.05313v1](http://arxiv.org/abs/2506.05313v1)|null|
|**2025-06-05**|**Big Bird: Privacy Budget Management for W3C's Privacy-Preserving Attribution API**|Pierre Tholoniat et.al.|[2506.05290v1](http://arxiv.org/abs/2506.05290v1)|null|
|**2025-06-05**|**EOC-Bench: Can MLLMs Identify, Recall, and Forecast Objects in an Egocentric World?**|Yuqian Yuan et.al.|[2506.05287v1](http://arxiv.org/abs/2506.05287v1)|null|
